```python
ubuntu  tar 
解包:tar xvf FileName.tar 
打包:tar cvf FileName.tar DirName 
```



```python
scrapy view 连接
这样就会
```



```python
cookie池
网站需要登陆才可以爬去，例如新浪微博
爬取过程中如果频类过高会导致封号
把 cookie放入请求头，就可以完成登录后的抓取
在cookie池里维护，随机取出cookie赋值到请求头里面，进行随机抓取就可以了，这样每个账号请求的频率就低了下来
需要维护多个账号的Cookie池实现大规模的抓取

cookie池的要求
实现账号的自动化登陆，可以把账号存到数据库里面，然后用这些账号，分别请求登陆页面，登陆成功之后，把登陆成功的COOKIE拿过来，放到COOKIE池里面
1.自动登陆更新
2.定时验证筛选
3.提供外部接口

利用三大模块
生成器
定时检测器
API 
利用这三大模块完成cookies池的架构的时间
```



![](C:\Users\dream\Desktop\gitscrapy\微信图片_20180708185008.png)











































